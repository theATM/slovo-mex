{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a id='task4'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Assigment.</b> <b>Task 4.</b>\n",
    "\n",
    "Use features calculated for each modality in task 3. Choose base classifier for each modality from scikit-learn. Train classifiers for each modality feature presentations separately and combine the outputs in decision level. Evaluate and compare the result on testing dataset. Do the subtasks given as\n",
    "<br>\n",
    "<br>\n",
    "<p> <b>4.1</b> Use base classifiers of support vector machine (SVM) with RBF-kernel and AdaBoost classifier (with random_state=0).\n",
    "Normalize data between 0-1 using the training dataset. Train the base classifiers by tuning the model parameters (<i>C</i> parameter and RBF-kernel <i>gamma</i> in SVM as well as <i>n_estimators</i> and <i>learning_rate</i> in Adaboost) using 10-fold cross-validation on training dataset to find optimal set of parameters (hint: use GridSearchCV from scikit-learn). For grid search use the following values $C = [0.1, 1.0, 10.0, 100.0]$, $gamma=[0.1, 0.25, 0.5, 0.75, 1.0, 2.0]$, $n\\_estimators = [50, 100, 500, 1000]$, and $learning\\_rate = [0.1, 0.25, 0.5, 0.75,1.0]$. Choose the best parameters and train the classifiers for each modality on whole training dataset. Is there a possibility that classifiers will overfit to training data using this parameter selection strategy? If so, why? </p>\n",
    "<br>\n",
    "<p> <b>4.2</b> Predict probabilistic outputs of each trained classifier for both modalities using the test set. </p>\n",
    "<br>\n",
    "<p> <b>4.3</b> Combine the probabilistic outputs of different modalities by fixed classification rules: max, min, prod, and sum. Evaluate, compare, and analyse the final combined results using confusion matrices and F1 scores. Show results for each base classifier combinations (i.e., $SVM_{acc}+SVM_{depth}$, $AdaBoost_{acc}+AdaBoost_{depth}$, $SVM_{acc}+AdaBoost_{depth}$, $AdaBoost_{acc}+SVM_{depth}$)</p>\n",
    "<br>\n",
    "Document your work, evaluate the results, and analyse the outcomes in each subtasks 4.1-4.3.\n",
    "\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import importlib, utilities.fun_four, utilities.fun_one\n",
    "importlib.reload(utilities.fun_four)\n",
    "importlib.reload(utilities.fun_one)\n",
    "from utilities.fun_four import DataNormalizer, GridClassifier, svm_classify, ada_classify, combine_probabilities, combine_visualize\n",
    "from utilities.fun_one import visualize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Get the training data form the notebook slovo_one:\n",
    "%store -r train_records_merged\n",
    "df_records_windowed = train_records_merged\n",
    "%store -r test_records_merged\n",
    "df_records_windowed = test_records_merged"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "act_train = np.concatenate(train_records_merged.df_y.values)\n",
    "act_test = np.concatenate(test_records_merged.df_y.values)\n",
    "act_train_labels = np.array(train_records_merged.exercise_id.apply(lambda x: int(x)))\n",
    "act_test_labels = np.array(test_records_merged.exercise_id.apply(lambda x: int(x)))\n",
    "\n",
    "\n",
    "dc_train = np.concatenate(train_records_merged.df_x.values)\n",
    "dc_test = np.concatenate(test_records_merged.df_x.values)\n",
    "dc_train_labels = np.array(train_records_merged.exercise_id.apply(lambda x: int(x)))\n",
    "dc_test_labels = np.array(test_records_merged.exercise_id.apply(lambda x: int(x)))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Normalize the data:\n",
    "act_normalizer = DataNormalizer()\n",
    "act_normalizer.fit(act_train)\n",
    "act_train = act_normalizer.transform(act_train)\n",
    "act_test = act_normalizer.transform(act_test)\n",
    "\n",
    "dc_normalizer = DataNormalizer()\n",
    "dc_normalizer.fit(dc_train)\n",
    "dc_train = dc_normalizer.transform(dc_train)\n",
    "dc_test = dc_normalizer.transform(dc_test)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Classification accelerometer data:\n",
    "act_svm_best = svm_classify(act_train,act_train_labels,act_test)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "act_ada_best = ada_classify(act_train,act_train_labels,act_test)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Classification depth camera data:\n",
    "dc_svm_best  = svm_classify(dc_train,dc_train_labels,dc_test)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "dc_ada_best = ada_classify(dc_train,dc_train_labels,dc_test)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# 4.2 Get the predictions:\n",
    "act_svm_pred_train = act_svm_best.predict(act_train)\n",
    "act_svm_pred_test = act_svm_best.predict(act_test)\n",
    "act_svm_proba_train = act_svm_best.predict_proba(act_train)\n",
    "act_svm_proba_test = act_svm_best.predict_proba(act_test)\n",
    "\n",
    "act_ada_pred_train = act_ada_best.predict(act_train)\n",
    "act_ada_pred_test = act_ada_best.predict(act_test)\n",
    "act_ada_proba_train = act_ada_best.predict_proba(act_train)\n",
    "act_ada_proba_test = act_ada_best.predict_proba(act_test)\n",
    "\n",
    "dc_svm_pred_train =  dc_svm_best.predict(dc_train)\n",
    "dc_svm_pred_test =   dc_svm_best.predict(dc_test)\n",
    "dc_svm_proba_train = dc_svm_best.predict_proba(dc_train)\n",
    "dc_svm_proba_test =  dc_svm_best.predict_proba(dc_test)\n",
    "\n",
    "dc_ada_pred_train =  dc_ada_best.predict(dc_train)\n",
    "dc_ada_pred_test =   dc_ada_best.predict(dc_test)\n",
    "dc_ada_proba_train = dc_ada_best.predict_proba(dc_train)\n",
    "dc_ada_proba_test =  dc_ada_best.predict_proba(dc_test)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation Accelerometer with svm:\n",
    "visualize(act_svm_pred_train,act_train_labels,act_svm_pred_test,act_test_labels,main_title=\"Accelerometer sensor used with svm to classify the exercises\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation Accelerometer with ada boost:\n",
    "visualize(act_ada_pred_train,act_train_labels,act_ada_pred_test,act_test_labels,main_title=\"Accelerometer sensor used with ada boost to classify the exercises\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation Depth Camera with svm:\n",
    "visualize(dc_svm_pred_train,dc_train_labels,dc_svm_pred_test,dc_test_labels,main_title=\"Depth Camera sensor used with svm to classify the exercises\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation Depth Camera with ada boost:\n",
    "visualize(dc_ada_pred_train,dc_train_labels,dc_ada_pred_test,dc_test_labels,main_title=\"Depth Camera sensor used with ada boost to classify the exercises\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ground_truth_train = act_train_labels # They are equal to the dc_train_labels\n",
    "ground_truth_test = act_test_labels\n",
    "\n",
    "# Combine predictions SVM-act and SVM-dc\n",
    "svm2_train, svm2_test = combine_probabilities(act_svm_proba_train,dc_svm_proba_train,\n",
    "                                              act_svm_proba_test,dc_svm_proba_test)\n",
    "# Combine predictions SVM-act and Ada-dc\n",
    "svmad_train, svmad_test = combine_probabilities(act_svm_proba_train,dc_ada_proba_train,\n",
    "                                              act_svm_proba_test,dc_ada_proba_test)\n",
    "# Combine predictions Ada-act and Ada-dc\n",
    "ada2_train, ada2_test = combine_probabilities(act_ada_proba_train,dc_ada_proba_train,\n",
    "                                              act_ada_proba_test,dc_ada_proba_test)\n",
    "# Combine predictions Ada-act and SVM-dc\n",
    "adasv_train, adasv_test = combine_probabilities(act_ada_proba_train,dc_ada_proba_train,\n",
    "                                              act_ada_proba_test,dc_ada_proba_test)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Visualize\n",
    "# Combine predictions SVM-act and SVM-dc\n",
    "combine_visualize(svm2_train,ground_truth_train,svm2_test,ground_truth_test,\"SVM-act and SVM-dc\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combine predictions SVM-act and Ada-dc\n",
    "combine_visualize(svmad_train,ground_truth_train,svmad_test,ground_truth_test,\"SVM-act and Ada-dc\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combine predictions Ada-act and Ada-dc\n",
    "combine_visualize(ada2_train,ground_truth_train,ada2_test,ground_truth_test,\"Ada-act and Ada-dc\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combine predictions Ada-act and SVM-dc\n",
    "combine_visualize(adasv_train,ground_truth_train,adasv_test,ground_truth_test,\"Ada-act and SVM-dc\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
