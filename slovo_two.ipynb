{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Feature extraction and fusion for unimodal classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='task2'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Assigment.</b> <b>Task 2.</b>\n",
    "\n",
    "Use the training dataset prepared in task 1. to build models based on the combination of principal component analysis (PCA), linear discriminant analysis (LDA), and nearest neighbour (NN) classifier for each modality separately and evaluate the model on test dataset. Do the subtasks given as\n",
    "<br>\n",
    "<br>\n",
    "<p> <b>2.1</b> Calculate PCA and LDA transformations to reduce the dimensionality of accelerometer data (e.g., using scikit-learn implementations). Before transformations downsample data from 100 Hz to 25 Hz (using scipy.signal.resample) to get 125x3 matrix of data for each 5 sec window. You should also standardize the values to zero mean and unit variance before the transformations. Using training dataset, fit PCA with 5-dimensional subspace (i.e., choosing the 5 largest principal components) and fit LDA with 5-dimensional subspace. Transform both train and test examples to this low-dimensional feature representation. Concatenate each sequence to single vector size of 3x(5+5). Perform the fusion of PCA and LDA similar manner as presented in Lecture 3 (pages 24-25) using NN method. Evaluate the performance on testset. Show confusion matrix and F1 scores of the results. </p>\n",
    "<br>\n",
    "<p> <b>2.2</b> Use PCA and LDA transformations to reduce the dimensionality of depth images. You should also standardize the values to zero mean and unit variance before the transformations. Fit PCA and LDA for all training images (12x16, 192-dimensional in vectorized form) by choosing 5-dimensional subspace for both PCA and LDA. Transform both train and test examples to this low-dimensional feature representation. Concatenate each sequence to single vector size of 5x1x(5+5). Similar to task 2.1, do the PCA and LDA fusion using NN and evaluate the performance on testset. Show confusion matrix and F1 scores of the results. </p>\n",
    "<br>\n",
    "Document your work, evaluate the results, and analyse the outcomes in each subtasks 2.1-2.2.\n",
    "\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Calculate PCA and LDA transformations to reduce the dimensionality of accelerometer data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run task one first to get training and testing records (Task 1.2)\n",
    "# If you have run task one yourself before you can skip this cell\n",
    "%%capture\n",
    "%run ./slovo_one.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load training and testing data from task one:\n",
    "%store -r training_records\n",
    "training_records = training_records\n",
    "%store -r testing_records\n",
    "testing_records = testing_records"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2.1 Imports:\n",
    "import importlib, utilities.fun_two, utilities.fun_one\n",
    "importlib.reload(utilities.fun_two)\n",
    "importlib.reload(utilities.fun_one)\n",
    "from utilities.fun_two import acccelerometer_resample, PcaActApplier, LdaActApplier, act_fusion, Standardizer\n",
    "from utilities.fun_one import visualize\n",
    "import time\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Resample the data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Your code begins here ###\n",
    "#Measure time\n",
    "start_time = time.time()\n",
    "# number of samples to be left in a window\n",
    "resample_samples = 125\n",
    "# Resample training data using signal's resample:\n",
    "act_train = pd.DataFrame()\n",
    "act_train['df'] = acccelerometer_resample(training_records,resample_samples)\n",
    "train_labels = training_records[training_records.sensor_code=='act'].exercise_id.apply(lambda x: int(x))\n",
    "# Resample testing data:\n",
    "act_test = pd.DataFrame()\n",
    "act_test['df'] = acccelerometer_resample(testing_records,resample_samples)\n",
    "#Get Labels:\n",
    "test_labels = testing_records[testing_records.sensor_code=='act'].exercise_id.apply(lambda x: int(x))\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Standardize the Data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Measure time\n",
    "start_time = time.time()\n",
    "# Create a Standardizer:\n",
    "act_s = Standardizer()\n",
    "# Calculate mean and std on training set:\n",
    "act_s.fit(act_train)\n",
    "# Using mean and std standardize training set:\n",
    "act_train['df'] = act_s.transform(act_train)\n",
    "# Using training set mean and std standardize test set:\n",
    "act_test['df'] = act_s.transform(act_test)\n",
    "# Measure execution time\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Apply the PCA - calculate 5 principal components:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Measure time\n",
    "start_time = time.time()\n",
    "# choose 5 principal components:\n",
    "n_components = 5\n",
    "# Create Pca decorator class object:\n",
    "pca = PcaActApplier(n_components)\n",
    "# Fit the PCA with the training data\n",
    "pca.fit(act_train['df'])\n",
    "# Apply PCA on both training and testing data:\n",
    "act_pca_train = pca.transform(act_train['df'])\n",
    "act_pca_test = pca.transform(act_test['df'])\n",
    "# Measure execution time\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Apply the LDA:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Measure time\n",
    "start_time = time.time()\n",
    "# LDA, number of components for dimensionality reduction:\n",
    "n_components = 5\n",
    "# LDA decorator:\n",
    "lda = LdaActApplier(n_components)\n",
    "# Fit with training data:\n",
    "lda.fit(act_train['df'],train_labels)\n",
    "# Transform both sets:\n",
    "act_lda_train = lda.transform(act_train['df'])\n",
    "act_lda_test = lda.transform(act_test['df'])\n",
    "# Measure execution time:\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### PCA and LDA Fusion of accelerometer data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Measure time\n",
    "start_time = time.time()\n",
    "# Fuse training pca and lda to get a NN classification for comparison:\n",
    "train_pred_labels = act_fusion(act_pca_train,act_lda_train,act_pca_train,act_lda_train,train_labels)\n",
    "# Fuse testing data to get testing label predictions:\n",
    "test_pred_labels = act_fusion(act_pca_train,act_lda_train,act_pca_test,act_lda_test,train_labels)\n",
    "# Measure execution time:\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualisation of the nearest neighbour classification on the accelerometer data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Run visualize function (prints confusion matrix and calculates f1 score)\n",
    "# To see how predicted labels on testing data are correct\n",
    "visualize(train_pred_labels,train_labels,test_pred_labels,test_labels,main_title=\"Accelerometer sensor used to classify the exercises\")\n",
    "### Your code ends here ###"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Discussion\n",
    "As one can see the results for the testing set shown on the confusion matrix and the F1 score = 0.4616, aren't satisfactory.\n",
    "This may be due to the similarity between the exercises and differences between the subjects.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Use PCA and LDA transformations to reduce the dimensionality of depth images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2.2 Imports:\n",
    "import importlib, utilities.fun_two, utilities.fun_one\n",
    "importlib.reload(utilities.fun_two)\n",
    "importlib.reload(utilities.fun_one)\n",
    "from utilities.fun_two import concat_pca_lda, PcaDcApplier, LdaDcApplier, classifyNN, Standardizer\n",
    "from utilities.fun_one import visualize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Your code begins here ###\n",
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "'''Work only with rows with dc'''\n",
    "dc_train_records = training_records[training_records['sensor'] == 'dc']\n",
    "dc_test_records = testing_records[testing_records['sensor'] == 'dc']\n",
    "\n",
    "reduced_dimensions = 5\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "'''Standardize the dc data'''\n",
    "standardizer = Standardizer()\n",
    "standardizer.fit(dc_train_records)\n",
    "standardized_dc_train_records = standardizer.transform(dc_train_records)\n",
    "standardized_dc_test_records = standardizer.transform(dc_test_records)\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "'''Fit PCA for depth sensor on standardized train dataset and transform test an train dataset'''\n",
    "pca_applier = PcaDcApplier(reduced_dimensions)\n",
    "pca_applier.fit(standardized_dc_train_records)\n",
    "\n",
    "pca_dc_train_records = pca_applier.transform(standardized_dc_train_records)\n",
    "pca_dc_test_records = pca_applier.transform(standardized_dc_test_records)\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "'''Fit PCA for depth sensor on standardized train dataset and transform test an train dataset'''\n",
    "lda_applier = LdaDcApplier(reduced_dimensions)\n",
    "lda_applier.fit(standardized_dc_train_records)\n",
    "\n",
    "lda_dc_train_records = lda_applier.transform(standardized_dc_train_records)\n",
    "lda_dc_test_records = lda_applier.transform(standardized_dc_test_records)\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "'''Concatenate PCA and LDA features of depth sensor data'''\n",
    "concat_dc_train_records = concat_pca_lda(pca_dc_train_records, lda_dc_train_records)\n",
    "concat_dc_test_records = concat_pca_lda(pca_dc_test_records, lda_dc_test_records)\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "'''Get estimated labels for train dataset calculated by Nearest Neighbour algorithm on depth sensor data'''\n",
    "est_train_labels = classifyNN(train_data = concat_dc_train_records, test_data=concat_dc_train_records)\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "'''Get estimated labels for test dataset calculated by Nearest Neighbour algorithm on depth sensor data'''\n",
    "est_test_labels = classifyNN(train_data = concat_dc_train_records, test_data=concat_dc_test_records)\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}