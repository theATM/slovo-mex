{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Feature extraction and fusion for unimodal classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='task2'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Assigment.</b> <b>Task 2.</b>\n",
    "\n",
    "Use the training dataset prepared in task 1. to build models based on the combination of principal component analysis (PCA), linear discriminant analysis (LDA), and nearest neighbour (NN) classifier for each modality separately and evaluate the model on test dataset. Do the subtasks given as\n",
    "<br>\n",
    "<br>\n",
    "<p> <b>2.1</b> Calculate PCA and LDA transformations to reduce the dimensionality of accelerometer data (e.g., using scikit-learn implementations). Before transformations downsample data from 100 Hz to 25 Hz (using scipy.signal.resample) to get 125x3 matrix of data for each 5 sec window. You should also standardize the values to zero mean and unit variance before the transformations. Using training dataset, fit PCA with 5-dimensional subspace (i.e., choosing the 5 largest principal components) and fit LDA with 5-dimensional subspace. Transform both train and test examples to this low-dimensional feature representation. Concatenate each sequence to single vector size of 3x(5+5). Perform the fusion of PCA and LDA similar manner as presented in Lecture 3 (pages 24-25) using NN method. Evaluate the performance on testset. Show confusion matrix and F1 scores of the results. </p>\n",
    "<br>\n",
    "<p> <b>2.2</b> Use PCA and LDA transformations to reduce the dimensionality of depth images. You should also standardize the values to zero mean and unit variance before the transformations. Fit PCA and LDA for all training images (12x16, 192-dimensional in vectorized form) by choosing 5-dimensional subspace for both PCA and LDA. Transform both train and test examples to this low-dimensional feature representation. Concatenate each sequence to single vector size of 5x1x(5+5). Similar to task 2.1, do the PCA and LDA fusion using NN and evaluate the performance on testset. Show confusion matrix and F1 scores of the results. </p>\n",
    "<br>\n",
    "Document your work, evaluate the results, and analyse the outcomes in each subtasks 2.1-2.2.\n",
    "\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 Calculate PCA and LDA transformations to reduce the dimensionality of accelerometer data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2.1 Imports:\n",
    "import importlib, utilities.fun_two, utilities.fun_one\n",
    "importlib.reload(utilities.fun_two)\n",
    "importlib.reload(utilities.fun_one)\n",
    "from utilities.fun_two import acccelerometer_resample, PcaActApplier, LdaActApplier, act_fusion, Standardizer\n",
    "from utilities.fun_one import visualize\n",
    "import time\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%store -r training_records\n",
    "training_records = training_records\n",
    "%store -r testing_records\n",
    "testing_records = testing_records"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Your code begins here ###\n",
    "# Resample data:\n",
    "resample_samples = 125\n",
    "act_train = pd.DataFrame()\n",
    "act_train['df'] = acccelerometer_resample(training_records,resample_samples)\n",
    "train_labels = training_records[training_records.sensor_code=='act'].exercise_id.apply(lambda x: int(x))\n",
    "act_test = pd.DataFrame()\n",
    "act_test['df'] = acccelerometer_resample(testing_records,resample_samples)\n",
    "test_labels = testing_records[testing_records.sensor_code=='act'].exercise_id.apply(lambda x: int(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "#Standardize the Data:\n",
    "act_s = Standardizer()\n",
    "act_s.fit(act_train)\n",
    "act_train['df'] = act_s.transform(act_train)\n",
    "act_test['df'] = act_s.transform(act_test)\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "#PCA\n",
    "n_components = 5\n",
    "pca = PcaActApplier(n_components)\n",
    "pca.fit(act_train['df'])\n",
    "act_pca_train = pca.transform(act_train['df'])\n",
    "act_pca_test = pca.transform(act_test['df'])\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "#LDA:\n",
    "n_components = 5\n",
    "lda = LdaActApplier(n_components)\n",
    "lda.fit(act_train['df'],train_labels)\n",
    "act_lda_train = lda.transform(act_train['df'])\n",
    "act_lda_test = lda.transform(act_test['df'])\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "# Fusion:\n",
    "train_pred_labels = act_fusion(act_pca_train,act_lda_train,act_pca_train,act_lda_train,train_labels)\n",
    "test_pred_labels = act_fusion(act_pca_train,act_lda_train,act_pca_test,act_lda_test,train_labels)\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation:\n",
    "visualize(train_pred_labels,train_labels,test_pred_labels,test_labels,main_title=\"Accelerometer sensor used to classify the exercises\")\n",
    "### Your code ends here ###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Use PCA and LDA transformations to reduce the dimensionality of depth images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2.2 Imports:\n",
    "import importlib, utilities.fun_two, utilities.fun_one\n",
    "importlib.reload(utilities.fun_two)\n",
    "importlib.reload(utilities.fun_one)\n",
    "from utilities.fun_two import concat_pca_lda, PcaDcApplier, LdaDcApplier, classifyNN, Standardizer\n",
    "from utilities.fun_one import visualize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Your code begins here ###\n",
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "'''Work only with rows with dc'''\n",
    "dc_train_records = training_records[training_records['sensor'] == 'dc']\n",
    "dc_test_records = testing_records[testing_records['sensor'] == 'dc']\n",
    "\n",
    "reduced_dimensions = 5\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "'''Standardize the dc data'''\n",
    "standardizer = Standardizer()\n",
    "standardizer.fit(dc_train_records)\n",
    "standardized_dc_train_records = standardizer.transform(dc_train_records)\n",
    "standardized_dc_test_records = standardizer.transform(dc_test_records)\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "'''Fit PCA for depth sensor on standardized train dataset and transform test an train dataset'''\n",
    "pca_applier = PcaDcApplier(reduced_dimensions)\n",
    "pca_applier.fit(standardized_dc_train_records)\n",
    "\n",
    "pca_dc_train_records = pca_applier.transform(standardized_dc_train_records)\n",
    "pca_dc_test_records = pca_applier.transform(standardized_dc_test_records)\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "'''Fit PCA for depth sensor on standardized train dataset and transform test an train dataset'''\n",
    "lda_applier = LdaDcApplier(reduced_dimensions)\n",
    "lda_applier.fit(standardized_dc_train_records)\n",
    "\n",
    "lda_dc_train_records = lda_applier.transform(standardized_dc_train_records)\n",
    "lda_dc_test_records = lda_applier.transform(standardized_dc_test_records)\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "'''Concatenate PCA and LDA features of depth sensor data'''\n",
    "concat_dc_train_records = concat_pca_lda(pca_dc_train_records, lda_dc_train_records)\n",
    "concat_dc_test_records = concat_pca_lda(pca_dc_test_records, lda_dc_test_records)\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "'''Get estimated labels for train dataset calculated by Nearest Neighbour algorithm on depth sensor data'''\n",
    "est_train_labels = classifyNN(train_data = concat_dc_train_records, test_data=concat_dc_train_records)\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time() # Measure execution time\n",
    "\n",
    "'''Get estimated labels for test dataset calculated by Nearest Neighbour algorithm on depth sensor data'''\n",
    "est_test_labels = classifyNN(train_data = concat_dc_train_records, test_data=concat_dc_test_records)\n",
    "\n",
    "end_time = time.time() # Measure execution time\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''Visualize the results of NN classification for depth sensor data'''\n",
    "visualize(est_train_labels['estimated_label'],est_train_labels['real_label'],est_test_labels['estimated_label'],est_test_labels['real_label'],main_title=\"Depth sensor used to classify the exercises\")\n",
    "### Your code ends here ###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
