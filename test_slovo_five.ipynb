{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Bonus task: Multimodal biometric identification of persons (optional)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='task5'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Assigment.</b> <b>Task 5.</b>\n",
    "\n",
    "Can you build a classifier that recognizes the person who is performing the exercise? Use same 10 person dataset and split it so that first 25% of each long exercise sequence is used for training and rest 75% of each sequence is used for testing the classifier. Use same 5 second windowing with 3 seconds overlap to prepare the examples. Note that, now the person identity is the class label instead of exercise type. Max. 10 points are given but you can earn points from partial solution, as well.\n",
    "<br>\n",
    "<br>\n",
    "<p> <b>5.1</b> Build a classifier to identify persons based on the features and one of the models given in task 4 (max. 5 points).</p>\n",
    "<br>\n",
    "<p> <b>5.2</b> Can you build your own solution (using new features, new classification model or different fusion approaches) to beat the approach in Task 5.1 ? (max. 5 points) </p>\n",
    "<br>\n",
    "Document your work. Evaluate and compare the results using confusion matrix and F1 score.\n",
    "\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run ./slovo_three.ipynb ;"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import importlib, utilities.fun_five, utilities.fun_four, utilities.fun_three, utilities.fun_two, utilities.fun_one\n",
    "importlib.reload(utilities.fun_five)\n",
    "importlib.reload(utilities.fun_four)\n",
    "importlib.reload(utilities.fun_three)\n",
    "importlib.reload(utilities.fun_two)\n",
    "importlib.reload(utilities.fun_one)\n",
    "from utilities.fun_five import data_resample, filter_dataframe\n",
    "from utilities.fun_three import reshape_dataframe\n",
    "from utilities.fun_four import combine_visualize, ArrayNormalizer, GridClassifier, svm_classify, ada_classify, combine_probabilities, clf_classify\n",
    "from utilities.fun_two import *\n",
    "from utilities.fun_one import visualize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%store -r df_records_windowed\n",
    "df_records_windowed = df_records_windowed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#splt the data into training and testing sets:\n",
    "\n",
    "#Merge dc and act to one row (one act without dc is omitted)\n",
    "records_merged = df_records_windowed[df_records_windowed.sensor_code=='dc'].merge(df_records_windowed[df_records_windowed.sensor_code=='act'], on=['subject_id', 'exercise_id', 'trial', 'window_idx'])\n",
    "\n",
    "\n",
    "train_records, test_records = filter_dataframe(records_merged,ratio=0.25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_records"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_records"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5.1\n",
    "\n",
    "### Your code begins here ###\n",
    "\n",
    "# Standardize the Data:\n",
    "act_s = Standardizer()\n",
    "act_s.fit(train_records,df_name='df_y')\n",
    "train_records = act_s.transform(train_records,df_name='df_y')\n",
    "test_records = act_s.transform(test_records,df_name='df_y')\n",
    "\n",
    "dc_s = Standardizer()\n",
    "dc_s.fit(train_records,df_name='df_x')\n",
    "train_records = dc_s.transform(train_records,df_name='df_x')\n",
    "test_records = dc_s.transform(test_records,df_name='df_x')\n",
    "\n",
    "labels_train = np.array(train_records.exercise_id.apply(lambda x: int(x)))\n",
    "labels_test = np.array(test_records.exercise_id.apply(lambda x: int(x)))\n",
    "\n",
    "\n",
    "train_raw_records = train_records\n",
    "test_raw_records = test_records\n",
    "\n",
    "%store train_raw_records\n",
    "%store test_raw_records\n",
    "\n",
    "#ACT : -----------------\n",
    "# Apply PCA:\n",
    "n_components = 5\n",
    "pca = PcaActApplier(n_components)\n",
    "pca.fit(train_records['df_y'])\n",
    "act_pca_train = pca.transform(train_records['df_y'])\n",
    "act_pca_test = pca.transform(test_records['df_y'])\n",
    "\n",
    "#LDA:\n",
    "n_components = 1\n",
    "lda = LdaActApplier(n_components)\n",
    "lda.fit(train_records['df_y'],labels_train)\n",
    "act_lda_train = lda.transform(train_records['df_y'])\n",
    "act_lda_test = lda.transform(test_records['df_y'])\n",
    "\n",
    "act_features = np.concatenate((act_pca_train[0],act_pca_train[1],act_pca_train[2],\n",
    "                               act_lda_train[0],act_lda_train[1],act_lda_train[2],\n",
    "                               np.mean(act_pca_train[0],axis=1).reshape(-1,1), np.std(act_pca_train[0],axis=1).reshape(-1,1),\n",
    "                               np.mean(act_pca_train[1],axis=1).reshape(-1,1), np.std(act_pca_train[1],axis=1).reshape(-1,1),\n",
    "                               np.mean(act_pca_train[2],axis=1).reshape(-1,1), np.std(act_pca_train[2],axis=1).reshape(-1,1),\n",
    "                              ),axis=1)\n",
    "\n",
    "act_test_features = np.concatenate((act_pca_test[0],act_pca_test[1],act_pca_test[2],\n",
    "                                    act_lda_test[0],act_lda_test[1],act_lda_test[2],\n",
    "                                    np.mean(act_pca_test[0],axis=1).reshape(-1,1), np.std(act_pca_test[0],axis=1).reshape(-1,1),\n",
    "                                    np.mean(act_pca_test[1],axis=1).reshape(-1,1), np.std(act_pca_test[1],axis=1).reshape(-1,1),\n",
    "                                    np.mean(act_pca_test[2],axis=1).reshape(-1,1), np.std(act_pca_test[2],axis=1).reshape(-1,1),\n",
    "                                   ),axis=1)\n",
    "# DC -------------------\n",
    "#PCA\n",
    "\n",
    "n_components = 10\n",
    "pca_applier = PcaDcApplier(n_components)\n",
    "pca_applier.fit(train_records,df_name='df_x')\n",
    "pca_dc_training_records = pca_applier.transform(train_records,df_name='df_x')\n",
    "pca_dc_testing_records = pca_applier.transform(test_records,df_name='df_x')\n",
    "\n",
    "pca_dc_training_records_reshaped = deepcopy(pca_dc_training_records)\n",
    "pca_dc_training_records_reshaped[\"df_x\"] = pca_dc_training_records_reshaped[\"df_x\"].apply(reshape_dataframe)\n",
    "pca_dc_testing_records_reshaped = deepcopy(pca_dc_testing_records)\n",
    "pca_dc_testing_records_reshaped[\"df_x\"] = pca_dc_testing_records_reshaped[\"df_x\"].apply(reshape_dataframe)\n",
    "\n",
    "dc_features = np.concatenate(pca_dc_training_records_reshaped['df_x'].values,axis=0)\n",
    "dc_test_features = np.concatenate(pca_dc_testing_records_reshaped['df_x'].values,axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Normalize the data:\n",
    "act_normalizer = ArrayNormalizer()\n",
    "act_normalizer.fit(act_features,axis=0)\n",
    "act_features = act_normalizer.transform(act_features)\n",
    "act_test_features = act_normalizer.transform(act_test_features)\n",
    "\n",
    "dc_normalizer = ArrayNormalizer()\n",
    "dc_normalizer.fit(dc_features,axis=None)\n",
    "dc_features = dc_normalizer.transform(dc_features)\n",
    "dc_test_features = dc_normalizer.transform(dc_test_features)\n",
    "\n",
    "#Save for use in other notebooks:\n",
    "%store act_features\n",
    "%store act_test_features\n",
    "%store labels_train\n",
    "%store labels_test\n",
    "%store dc_features\n",
    "%store dc_test_features\n",
    "\n",
    "### Your code ends here ###"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Classification\n",
    "act_gridsearch_kfold = 10\n",
    "dc_gridsearch_kfold = 10\n",
    "act_svm_params = {'C' : [0.1, 1.0, 10.0, 100.0], 'gamma' : [0.1, 0.25, 0.5, 0.75, 1.0, 2.0]}\n",
    "dc_svm_params = {'C' : [0.1, 1.0, 10.0, 100.0], 'gamma' : [0.1, 0.25, 0.5, 0.75, 1.0, 2.0]}\n",
    "\n",
    "act_svm_best = svm_classify(act_features,labels_train,act_test_features,svm_params=act_svm_params,kfold=act_gridsearch_kfold)\n",
    "\n",
    "dc_svm_best  = svm_classify(dc_features,labels_train,dc_test_features,svm_params=dc_svm_params,kfold=dc_gridsearch_kfold)\n",
    "\n",
    "print(f\"Act model parameters C = {act_svm_best.C} gamma = {act_svm_best.gamma}\")\n",
    "print(f\"Dc model parameters C = {dc_svm_best.C} gamma = {dc_svm_best.gamma}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#from sklearn import svm\n",
    "#act_svm_best = svm.SVC(C=0.1, kernel='poly',degree=5, gamma=0.5, random_state=0,probability=True, class_weight={1:0.5,2:1,3:1,4:0.5,5:0.5,6:0.5,7:0.5})\n",
    "#act_svm_best.fit(act_features,labels_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#from sklearn.neural_network import MLPClassifier\n",
    "#act_svm_best = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(100, 200, 500, 200, 50), random_state=0)\n",
    "#act_svm_best.fit(act_features,labels_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the predictions:\n",
    "act_svm_pred_train = act_svm_best.predict(act_features)\n",
    "act_svm_pred_test = act_svm_best.predict(act_test_features)\n",
    "act_svm_proba_train = act_svm_best.predict_proba(act_features)\n",
    "act_svm_proba_test = act_svm_best.predict_proba(act_test_features)\n",
    "\n",
    "dc_svm_pred_train =  dc_svm_best.predict(dc_features)\n",
    "dc_svm_pred_test =   dc_svm_best.predict(dc_test_features)\n",
    "dc_svm_proba_train = dc_svm_best.predict_proba(dc_features)\n",
    "dc_svm_proba_test =  dc_svm_best.predict_proba(dc_test_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation Accelerometer with svm:\n",
    "visualize(act_svm_pred_train, labels_train, act_svm_pred_test, labels_test,\n",
    "          main_title=\"Accelerometer sensor used with svm to classify the subjects\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # Visualisation Depth Camera with svm:\n",
    "visualize(dc_svm_pred_train, labels_train, dc_svm_pred_test, labels_test,\n",
    "          main_title=\"Depth Camera sensor used with svm to classify the subjects\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Combine the sensours\n",
    "svm2_train, svm2_test = combine_probabilities(act_svm_proba_train, dc_svm_proba_train,\n",
    "                                              act_svm_proba_test, dc_svm_proba_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combine predictions SVM-act and SVM-dc\n",
    "combine_visualize(svm2_train, labels_train, svm2_test, labels_test, \"SVM-act and SVM-dc\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 5.2\n",
    "combined_features = np.concatenate((act_svm_proba_train, dc_svm_proba_train), axis=1)\n",
    "combined_features_test = np.concatenate((act_svm_proba_test, dc_svm_proba_test), axis=1)\n",
    "svm_params = {'C': [0.1, 1.0, 10.0, 100.0], 'gamma': [0.1, 0.25, 0.5, 0.75, 1.0, 2.0]}\n",
    "svm_meta = svm_classify(combined_features, labels_train, combined_features_test, svm_params=svm_params)\n",
    "\n",
    "#print('C=', svm_meta.C)\n",
    "#print('gamma=', svm_meta.gamma)\n",
    "\n",
    "### Your code ends here ###\n",
    "C = svm_meta.C\n",
    "gamma = svm_meta.gamma\n",
    "#svm_meta = svm.SVC(kernel='rbf', random_state=0, gamma=gamma, C=C)\n",
    "svm_meta.fit(combined_features, labels_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svm_pred_train = svm_meta.predict(combined_features)\n",
    "svm_pred_test = svm_meta.predict(combined_features_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize(svm_pred_train, labels_train, svm_pred_test, labels_test, \"Meta SVM-act and SVM-dc\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "params = {'n_estimators' : [5,10,20,25,30,35,40,45,50,60], 'max_depth' : [1,2,3,4,5,6,7,8,9,10]}\n",
    "clf = RandomForestClassifier(random_state=0,max_depth=5)\n",
    "clf_meta = clf_classify(combined_features, labels_train, combined_features_test, svm_params = params)\n",
    "clf = clf.fit(combined_features, labels_train)\n",
    "svm_pred_train =  clf.predict(combined_features)\n",
    "svm_pred_test =   clf.predict(combined_features_test)\n",
    "visualize(svm_pred_train,labels_train,svm_pred_test,labels_test,\"Random Forest\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Combine on the data level\n",
    "combined_features = np.concatenate((act_features,dc_features),axis=1)\n",
    "combined_test_features = np.concatenate((act_test_features,dc_test_features),axis=1)\n",
    "combined_params = {'C': [0.1, 1.0, 10.0, 100.0], 'gamma': [0.1, 0.25, 0.5, 0.75, 1.0, 2.0]}\n",
    "combined_svm = svm_classify(combined_features, labels_train, combined_test_features, svm_params=combined_params)\n",
    "pred_train = combined_svm.predict(combined_features)\n",
    "pred_test = combined_svm.predict(combined_test_features)\n",
    "\n",
    "visualize(pred_train, labels_train, pred_test, labels_test, \"Meta SVM-act and SVM-dc\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}