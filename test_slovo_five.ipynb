{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Bonus task: Multimodal biometric identification of persons (optional)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='task5'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Assigment.</b> <b>Task 5.</b>\n",
    "\n",
    "Can you build a classifier that recognizes the person who is performing the exercise? Use same 10 person dataset and split it so that first 25% of each long exercise sequence is used for training and rest 75% of each sequence is used for testing the classifier. Use same 5 second windowing with 3 seconds overlap to prepare the examples. Note that, now the person identity is the class label instead of exercise type. Max. 10 points are given but you can earn points from partial solution, as well.\n",
    "<br>\n",
    "<br>\n",
    "<p> <b>5.1</b> Build a classifier to identify persons based on the features and one of the models given in task 4 (max. 5 points).</p>\n",
    "<br>\n",
    "<p> <b>5.2</b> Can you build your own solution (using new features, new classification model or different fusion approaches) to beat the approach in Task 5.1 ? (max. 5 points) </p>\n",
    "<br>\n",
    "Document your work. Evaluate and compare the results using confusion matrix and F1 score.\n",
    "\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import importlib, utilities.fun_five, utilities.fun_four, utilities.fun_three, utilities.fun_two, utilities.fun_one\n",
    "importlib.reload(utilities.fun_five)\n",
    "importlib.reload(utilities.fun_four)\n",
    "importlib.reload(utilities.fun_three)\n",
    "importlib.reload(utilities.fun_two)\n",
    "importlib.reload(utilities.fun_one)\n",
    "from utilities.fun_five import data_resample, filter_dataframe\n",
    "from utilities.fun_three import reshape_dataframe\n",
    "from utilities.fun_four import combine_visualize, DataNormalizer, GridClassifier, svm_classify, ada_classify, combine_probabilities\n",
    "from utilities.fun_two import *\n",
    "from utilities.fun_one import visualize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%store -r df_records_windowed\n",
    "df_records_windowed = df_records_windowed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#splt the data into training and testing sets:\n",
    "\n",
    "#Merge dc and act to one row (one act without dc is omitted)\n",
    "records_merged = df_records_windowed[df_records_windowed.sensor_code=='dc'].merge(df_records_windowed[df_records_windowed.sensor_code=='act'], on=['subject_id', 'exercise_id', 'trial', 'window_idx'])\n",
    "\n",
    "\n",
    "train_records, test_records = filter_dataframe(records_merged,ratio=0.25)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5.1\n",
    "\n",
    "### Your code begins here ###\n",
    "\n",
    "# Standardize the Data:\n",
    "act_s = Standardizer()\n",
    "act_s.fit(train_records,df_name='df_y')\n",
    "train_records = act_s.transform(train_records,df_name='df_y')\n",
    "test_records = act_s.transform(test_records,df_name='df_y')\n",
    "\n",
    "dc_s = Standardizer()\n",
    "dc_s.fit(train_records,df_name='df_x')\n",
    "train_records = dc_s.transform(train_records,df_name='df_x')\n",
    "test_records = dc_s.transform(test_records,df_name='df_x')\n",
    "\n",
    "#ACT : -----------------\n",
    "# Apply PCA:\n",
    "n_components = 10\n",
    "pca = PcaActApplier(n_components)\n",
    "pca.fit(train_records['df_y'])\n",
    "act_pca_train = pca.transform(train_records['df_y'])\n",
    "act_pca_test = pca.transform(test_records['df_y'])\n",
    "\n",
    "act_features = np.concatenate((act_pca_train[0],act_pca_train[1],act_pca_train[2],\n",
    "                               np.mean(act_pca_train[0],axis=1).reshape(-1,1), np.std(act_pca_train[0],axis=1).reshape(-1,1),\n",
    "                               np.mean(act_pca_train[1],axis=1).reshape(-1,1), np.std(act_pca_train[1],axis=1).reshape(-1,1),\n",
    "                               np.mean(act_pca_train[2],axis=1).reshape(-1,1), np.std(act_pca_train[2],axis=1).reshape(-1,1),\n",
    "                              ),axis=1)\n",
    "\n",
    "act_test_features = np.concatenate((act_pca_test[0],act_pca_test[1],act_pca_test[2],\n",
    "                                    np.mean(act_pca_test[0],axis=1).reshape(-1,1), np.std(act_pca_test[0],axis=1).reshape(-1,1),\n",
    "                                    np.mean(act_pca_test[1],axis=1).reshape(-1,1), np.std(act_pca_test[1],axis=1).reshape(-1,1),\n",
    "                                    np.mean(act_pca_test[2],axis=1).reshape(-1,1), np.std(act_pca_test[2],axis=1).reshape(-1,1),\n",
    "                                   ),axis=1)\n",
    "# DC -------------------\n",
    "#PCA\n",
    "\n",
    "\n",
    "pca_applier = PcaDcApplier(n_components)\n",
    "pca_applier.fit(train_records,df_name='df_x')\n",
    "pca_dc_training_records = pca_applier.transform(train_records,df_name='df_x')\n",
    "pca_dc_testing_records = pca_applier.transform(test_records,df_name='df_x')\n",
    "\n",
    "pca_dc_training_records_reshaped = deepcopy(pca_dc_training_records)\n",
    "pca_dc_training_records_reshaped[\"df_x\"] = pca_dc_training_records_reshaped[\"df_x\"].apply(reshape_dataframe)\n",
    "pca_dc_testing_records_reshaped = deepcopy(pca_dc_testing_records)\n",
    "pca_dc_testing_records_reshaped[\"df_x\"] = pca_dc_testing_records_reshaped[\"df_x\"].apply(reshape_dataframe)\n",
    "\n",
    "dc_features = np.concatenate(pca_dc_training_records_reshaped['df_x'].values,axis=0)\n",
    "dc_test_features = np.concatenate(pca_dc_testing_records_reshaped['df_x'].values,axis=0)\n",
    "\n",
    "labels_train = np.array(train_records.exercise_id.apply(lambda x: int(x)))\n",
    "labels_test = np.array(test_records.exercise_id.apply(lambda x: int(x)))\n",
    "\n",
    "\n",
    "# Normalize the data:\n",
    "act_normalizer = DataNormalizer()\n",
    "act_normalizer.fit(act_features)\n",
    "act_features = act_normalizer.transform(act_features)\n",
    "act_test_features = act_normalizer.transform(act_test_features)\n",
    "\n",
    "dc_normalizer = DataNormalizer()\n",
    "dc_normalizer.fit(dc_features)\n",
    "dc_features = dc_normalizer.transform(dc_features)\n",
    "dc_test_features = dc_normalizer.transform(dc_test_features)\n",
    "\n",
    "# Classification\n",
    "act_svm_best = svm_classify(act_features,labels_train,act_test_features)\n",
    "dc_svm_best  = svm_classify(dc_features,labels_train,dc_test_features)\n",
    "\n",
    "# 4.2 Get the predictions:\n",
    "act_svm_pred_train = act_svm_best.predict(act_features)\n",
    "act_svm_pred_test = act_svm_best.predict(act_test_features)\n",
    "act_svm_proba_train = act_svm_best.predict_proba(act_features)\n",
    "act_svm_proba_test = act_svm_best.predict_proba(act_test_features)\n",
    "\n",
    "dc_svm_pred_train =  dc_svm_best.predict(dc_features)\n",
    "dc_svm_pred_test =   dc_svm_best.predict(dc_test_features)\n",
    "dc_svm_proba_train = dc_svm_best.predict_proba(dc_features)\n",
    "dc_svm_proba_test =  dc_svm_best.predict_proba(dc_test_features)\n",
    "\n",
    "\n",
    "### Your code ends here ###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation Accelerometer with svm:\n",
    "visualize(act_svm_pred_train, labels_train, act_svm_pred_test, labels_test,\n",
    "          main_title=\"Accelerometer sensor used with svm to classify the subjects\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation Depth Camera with svm:\n",
    "visualize(dc_svm_pred_train, labels_train, dc_svm_pred_test, labels_test,\n",
    "          main_title=\"Depth Camera sensor used with svm to classify the subjects\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Combine the sensours\n",
    "svm2_train, svm2_test = combine_probabilities(act_svm_proba_train, dc_svm_proba_train,\n",
    "                                              act_svm_proba_test, dc_svm_proba_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Combine predictions SVM-act and SVM-dc\n",
    "combine_visualize(svm2_train, labels_train, svm2_test, labels_test, \"SVM-act and SVM-dc\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
