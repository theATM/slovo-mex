{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a id='task1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Assigment.</b> <b>Task 1.</b>\n",
    "\n",
    "Download data from the Moodle's Project section. Get yourself familiar with the folder structure and data. You can read the data files using the function given below. Each file consists one exercise type performed by single user. Data are divided on multiple folders. Note that, in each folder there is one long sequence of single exercise, except exercise 4 which is performed two times in different ways. Those two sequences belongs to same class. Do the following subtasks to pre-analyse data examples and to prepare the training and testing data for next tasks:\n",
    "<br>\n",
    "<br>\n",
    "<p> Read raw data from the files. Prepare and divide each data file to shorter sequences using windowing method. Similar to related article \"MEx: Multi-modal Exercises Dataset for Human Activity Recognition\", use 5 second window and 3 second overlapping between windows, producing several example sequences from one exercise file for classification purposes. Windowing is working so that starting from the beginning of each long exercise sequence, take 5 seconds of data points (from synchronized acceleration data and depth images) based on the time stamps. Next, move the window 2 seconds forward and take another 5 seconds of data. Then continue this until your are at the end of sequence. Each window will consists 500x3 matrix of acceleration data and 5x192 matrix of depth image data.</p>\n",
    "<br>\n",
    "<p> <b>1.1</b> Plot few examples of prepared data for each modalities (accelometer and depth camera). Plot acceleration sensor as multi-dimensional time-series and depth camera data as 2D image. Plot 5 second acceleration sensor and depth image sequences of person 1 and 5 performing exercises 2, 5, and 6. Take the first windowed example from the long exercise sequence. </p>\n",
    "<br>\n",
    "<p> <b>1.2</b> Split the prepared dataset to training and testing datasets so that data of persons 1-7 are used for training and data of persons 8-10 are used for testing. In next tasks, training dataset could be further divided on (multiple) validation data folds to tune the models parameters, when needed.<br>\n",
    "\n",
    "<p> Note: Training set should have 1486 windows and testing set should have 598 windows. In training set, acceleration data will have a window without a pair with depth camera data, that window should be dropped as it doesn't have a pair.<p>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Document your work, calculate the indicator statistics of training and testing datasets (number of examples, dimensions of each example) and visualize prepared examples.\n",
    "\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import relevant libraries here\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Enter data folder location\n",
    "loc = \"./MEx\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find, read, and compose the measurements\n",
    "from utilities.fun_one import path_to_meta\n",
    "paths_record = Path(loc).glob(\"*/*/*.csv\")\n",
    "\n",
    "records = []\n",
    "\n",
    "for path_record in paths_record:\n",
    "    df = pd.read_csv(path_record, delimiter=\",\", header=None)\n",
    "    meta = path_to_meta(path_record)\n",
    "\n",
    "    if meta[\"sensor\"] == \"acc\":\n",
    "        col_names = [\"time\", \"acc_0\", \"acc_1\", \"acc_2\"]\n",
    "        df.columns = col_names\n",
    "    else:\n",
    "        num_cols = df.shape[1]\n",
    "        col_names = [\"time\", ] + [f\"dc_{i}\" for i in range(num_cols-1)]\n",
    "        df.columns = col_names\n",
    "\n",
    "    meta[\"df\"] = df\n",
    "\n",
    "    records.append(meta)\n",
    "\n",
    "df_records = pd.DataFrame.from_records(records)\n",
    "\n",
    "print(f\"Total records found: {len(df_records)}\")\n",
    "print(\"Dataframe with all records:\")\n",
    "display(df_records.head())\n",
    "print(\"Dataframe with one measurement series:\")\n",
    "display(df_records[\"df\"].iloc[0].head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extract 5-second long windows with 2-second shift (3-second overlap)\n",
    "\n",
    "records_windowed = []\n",
    "\n",
    "time_window = 5000.\n",
    "time_offset = 2000.\n",
    "\n",
    "for row_idx, row_data in df_records.iterrows():\n",
    "    df_tmp = row_data[\"df\"]\n",
    "    time_start = np.min(df_tmp[\"time\"].to_numpy())\n",
    "    time_end = np.max(df_tmp[\"time\"].to_numpy())\n",
    "\n",
    "    for window_idx, t0 in enumerate(np.arange(time_start, time_end, time_offset)):\n",
    "        t1 = t0 + time_window\n",
    "        # Handle boundary conditions - skip the measurements from the end shorter than window size\n",
    "        if t1 > time_end:\n",
    "            continue\n",
    "\n",
    "        tmp_data = deepcopy(row_data)\n",
    "        tmp_data[\"window_idx\"] = window_idx\n",
    "        tmp_data[\"df\"] = df_tmp[(df_tmp[\"time\"] >= t0) &\n",
    "                                (df_tmp[\"time\"] < t1)].copy()\n",
    "\n",
    "        records_windowed.append(tmp_data)\n",
    "\n",
    "df_records_windowed = pd.DataFrame.from_records(records_windowed)\n",
    "\n",
    "print(f\"Total windows extracted: {len(df_records_windowed)}\")\n",
    "print(\"Dataframe with all windowed records:\")\n",
    "display(df_records_windowed.head())\n",
    "print(\"Dataframe with one windowed measurement series:\")\n",
    "display(df_records_windowed[\"df\"].iloc[0].head())\n",
    "%store df_records_windowed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1. Visualize selected samples for both modalities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import importlib, utilities\n",
    "importlib.reload(utilities)\n",
    "from utilities.fun_one import visualize, visualize_acceleration, visualize_depth, visualize_depth_series"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation - Acceleration:\n",
    "%matplotlib inline\n",
    "print(\"Acceleration, Person 1, Exercise 2:\")\n",
    "visualize_acceleration(df_records_windowed,1,2)\n",
    "print(\"Acceleration, Person 1, Exercise 5:\")\n",
    "visualize_acceleration(df_records_windowed,1,5)\n",
    "print(\"Acceleration, Person 1, Exercise 6:\")\n",
    "visualize_acceleration(df_records_windowed,1,6)\n",
    "print(\"Acceleration, Person 5, Exercise 2:\")\n",
    "visualize_acceleration(df_records_windowed,5,2)\n",
    "print(\"Acceleration, Person 5, Exercise 5:\")\n",
    "visualize_acceleration(df_records_windowed,5,5)\n",
    "print(\"Acceleration, Person 5, Exercise 6:\")\n",
    "visualize_acceleration(df_records_windowed,5,6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Review of Accelerometer data visualisation\n",
    "The accelerometer data is presented as a series of charts each representing one subject doing one exercise. Plots present readings of 3D accelerometer over first time window (window index can be changed by the parameter of visualization function) of 5 seconds. We see that same exercises (e.g. Exe6) have similar characteristics (both have 1g acceleration over axis x, and almost 0 over other axes. Other exercises have different average distribution of acceleration over other axes).\n",
    "\n",
    "On the other hand Person 5, Exercise 2 has big bump over all axes, which is not present in the sample Person 1, Exercise 2. This may refer to some noise of the data. Maybe the sensor was hit by something."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation - Depth:\n",
    "%matplotlib inline\n",
    "print(\"Visualisation Depth Series, First Window:\")\n",
    "print(\"Person 1, Exercise 2:\")\n",
    "visualize_depth_series(df_records_windowed,1,2)\n",
    "print(\"Person 1, Exercise 5:\")\n",
    "visualize_depth_series(df_records_windowed,1,5)\n",
    "print(\"Person 1, Exercise 6:\")\n",
    "visualize_depth_series(df_records_windowed,1,6)\n",
    "print(\"Person 5, Exercise 2:\")\n",
    "visualize_depth_series(df_records_windowed,5,2)\n",
    "print(\"Person 5, Exercise 5:\")\n",
    "visualize_depth_series(df_records_windowed,5,5)\n",
    "print(\"Person 5, Exercise 6:\")\n",
    "visualize_depth_series(df_records_windowed,5,6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Review of the Depth sensor time series data visualization\n",
    "In the first part of visualization, we see channels arranged in a row, stacked over time series. The first thing to notice, that some channels (at the edges of the frame) have little variance, and they may not carry too much information. So the dimensionality reduction would be helpful"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Person 1, Exercise 2:\")\n",
    "%matplotlib notebook\n",
    "visualize_depth(df_records_windowed,1,2,None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Person 1, Exercise 5:\")\n",
    "%matplotlib notebook\n",
    "visualize_depth(df_records_windowed,1,5,None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Person 1, Exercise 6:\")\n",
    "%matplotlib notebook\n",
    "visualize_depth(df_records_windowed,1,6,None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Person 5, Exercise 2:\")\n",
    "%matplotlib notebook\n",
    "visualize_depth(df_records_windowed,5,2,None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Person 5, Exercise 5:\")\n",
    "%matplotlib notebook\n",
    "visualize_depth(df_records_windowed,5,5,None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Person 5, Exercise 6:\")\n",
    "%matplotlib notebook\n",
    "visualize_depth(df_records_windowed,5,6,None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Review of the Depth sensor data visualization as animated images\n",
    "Depth sensor data are presented as an animated sequence of images. There we can see not only the rough shape of test subject and his movements. Edges of the frame show no variance, as the subject is placed in the centre of the image. On the other hand, some pixels switch from 0 to 1 over time of one step in animation. This may indicate some false reading of the sensor."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2. Split samples based on subject ID into training and testing datasets for futher experiments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "importlib.reload(utilities.fun_one)\n",
    "from utilities.fun_one import stringify_id\n",
    "# 1.2. Split samples based on subject ID into training and testing datasets for futher experiments\n",
    "print(\"Splitting data into train ( persons 1-7 ) and test set (persons 8-10)\")\n",
    "\n",
    "#Create training and testing set by combining chosen subject data:\n",
    "training_records = df_records_windowed[(df_records_windowed.subject_id == stringify_id(1)) |\n",
    "                                       (df_records_windowed.subject_id == stringify_id(2)) |\n",
    "                                       (df_records_windowed.subject_id == stringify_id(3)) |\n",
    "                                       (df_records_windowed.subject_id == stringify_id(4)) |\n",
    "                                       (df_records_windowed.subject_id == stringify_id(5)) |\n",
    "                                       (df_records_windowed.subject_id == stringify_id(6)) |\n",
    "                                       (df_records_windowed.subject_id == stringify_id(7))]\n",
    "testing_records = df_records_windowed[(df_records_windowed.subject_id == stringify_id(8)) |\n",
    "                                      (df_records_windowed.subject_id == stringify_id(9)) |\n",
    "                                      (df_records_windowed.subject_id == stringify_id(10))]\n",
    "\n",
    "# Drop one row from training set which does not have a pair of sensor readings:\n",
    "training_records = training_records.drop(training_records.index[(training_records.subject_id == stringify_id(2)) &\n",
    "                                                                (training_records.exercise_id == stringify_id(6)) &\n",
    "                                                                (training_records.sensor_code == 'act') &\n",
    "                                                                (training_records.window_idx == 29)])\n",
    "\n",
    "\n",
    "#Save for use in other notebooks:\n",
    "%store training_records\n",
    "%store testing_records"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_records"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testing_records"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataframe description\n",
    "\n",
    "Overall length of datasets are **2972 samples in Train dataset** and **1196 samples in Test dataset**. This is because each time window is doubled for each modality (Depth sensor and Accelerometer) readings."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Overall length of training set: ', len(training_records))\n",
    "print('Overall length of testing set: ', len(testing_records))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lenghts of train and  test dataset for each modality (Depth sensor and Accelerometer) are then **598 samples in Train dataset** and **598 samples in Test dataset**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Length of accelerometer training set: ', len(training_records[training_records.sensor == 'acc']))\n",
    "print('Length of accelerometer testing set: ', len(testing_records[testing_records.sensor == 'acc']))\n",
    "print('Length of depth sensor training set: ', len(training_records[training_records.sensor == 'dc']))\n",
    "print('Length of depth sensor training set: ', len(testing_records[testing_records.sensor == 'dc']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Shape of the dataset is then number_of_samples*7. 7 refers to the columns of the dataset. At this point they don't represent the features of measured data, but rather metadata of each measurement. As in the display above, they hold **metadata** information like subject and sensor with which the sample of certain exercise was recorded."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Shape of train dataset: ', training_records.shape)\n",
    "print('Shape of test dataset: ', testing_records.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Actual measurements data\n",
    "\n",
    "The values of measurement's are held in the column 'df' containing data frames of each windowed recording. The properties of the dataframes vary among the sensor type (Accelerometer or Depth sensor) used to record the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Shape of accelerometer recording window with data values: ', training_records[training_records.sensor == 'acc'].iloc[0]['df'].shape)\n",
    "print('Shape of depth sensor recording window with data values: ', training_records[training_records.sensor == 'dc'].iloc[0]['df'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Accelerometer data\n",
    "\n",
    "Accelerometer data consist of readings of 3 accelerometer axis. Fist column represents time series and other 3 accelerometer axis. Values in the of the first sample range from -0.8 to 0.85, sou roughly from -1 to 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(training_records[training_records.sensor == 'acc'].iloc[0]['df'])\n",
    "print(\"Minimal value of dataframe: \", np.min(training_records[training_records.sensor == 'acc'].iloc[0]['df'].values[:,1:]))\n",
    "print(\"Maximal value of dataframe: \", np.max(training_records[training_records.sensor == 'acc'].iloc[0]['df'].values[:,1:]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Depth sensor data\n",
    "\n",
    "The shape of data indicates that one window consists of 5 images with 192 features (pixels). There is also one more feature, for time label. Values in the of the first sample range from 0 to 0.96, so roughly from 0 to 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(training_records[training_records.sensor == 'dc'].iloc[0]['df'])\n",
    "print(\"Minimal value of dataframe: \", np.min(training_records[training_records.sensor == 'dc'].iloc[0]['df'].values[:,1:]))\n",
    "print(\"Maximal value of dataframe: \", np.max(training_records[training_records.sensor == 'dc'].iloc[0]['df'].values[:,1:]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Person 5, Exercise 6:\")\n",
    "%matplotlib notebook\n",
    "visualize_depth(df_records_windowed,5,6,None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Review of the Depth sensor data visualization as animated images\n",
    "Depth sensor data are presented as an animated sequence of images. There we can see not only the rough shape of test subject and his movements. Edges of the frame show no variance, as the subject is placed in the centre of the image. On the other hand, some pixels switch from 0 to 1 over time of one step in animation. This may indicate some false reading of the sensor."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2. Split samples based on subject ID into training and testing datasets for futher experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "importlib.reload(utilities.fun_one)\n",
    "from utilities.fun_one import stringify_id\n",
    "# 1.2. Split samples based on subject ID into training and testing datasets for futher experiments\n",
    "print(\"Splitting data into train ( persons 1-7 ) and test set (persons 8-10)\")\n",
    "\n",
    "#Create training and testing set by combining chosen subject data:\n",
    "training_records = df_records_windowed[(df_records_windowed.subject_id == stringify_id(1)) |\n",
    "                                       (df_records_windowed.subject_id == stringify_id(2)) |\n",
    "                                       (df_records_windowed.subject_id == stringify_id(3)) |\n",
    "                                       (df_records_windowed.subject_id == stringify_id(4)) |\n",
    "                                       (df_records_windowed.subject_id == stringify_id(5)) |\n",
    "                                       (df_records_windowed.subject_id == stringify_id(6)) |\n",
    "                                       (df_records_windowed.subject_id == stringify_id(7))]\n",
    "testing_records = df_records_windowed[(df_records_windowed.subject_id == stringify_id(8)) |\n",
    "                                      (df_records_windowed.subject_id == stringify_id(9)) |\n",
    "                                      (df_records_windowed.subject_id == stringify_id(10))]\n",
    "\n",
    "# Drop one row from training set which does not have a pair of sensor readings:\n",
    "training_records = training_records.drop(training_records.index[(training_records.subject_id == stringify_id(2)) &\n",
    "                                                                (training_records.exercise_id == stringify_id(6)) &\n",
    "                                                                (training_records.sensor_code == 'act') &\n",
    "                                                                (training_records.window_idx == 29)])\n",
    "\n",
    "\n",
    "#Save for use in other notebooks:\n",
    "%store training_records\n",
    "%store testing_records"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_records"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testing_records"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataframe description\n",
    "\n",
    "Overall length of datasets are **2972 samples in Train dataset** and **1196 samples in Test dataset**. This is because each time window is doubled for each modality (Depth sensor and Accelerometer) readings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Overall length of training set: ', len(training_records))\n",
    "print('Overall length of testing set: ', len(testing_records))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lenghts of train and  test dataset for each modality (Depth sensor and Accelerometer) are then **598 samples in Train dataset** and **598 samples in Test dataset**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Length of accelerometer training set: ', len(training_records[training_records.sensor == 'acc']))\n",
    "print('Length of accelerometer testing set: ', len(testing_records[testing_records.sensor == 'acc']))\n",
    "print('Length of depth sensor training set: ', len(training_records[training_records.sensor == 'dc']))\n",
    "print('Length of depth sensor training set: ', len(testing_records[testing_records.sensor == 'dc']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Shape of the dataset is then number_of_samples*7. 7 refers to the columns of the dataset. At this point they don't represent the features of measured data, but rather metadata of each measurement. As in the display above, they hold **metadata** information like subject and sensor with which the sample of certain exercise was recorded."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Shape of train dataset: ', training_records.shape)\n",
    "print('Shape of test dataset: ', testing_records.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Actual measurements data\n",
    "\n",
    "The values of measurement's are held in the column 'df' containing data frames of each windowed recording. The properties of the dataframes vary among the sensor type (Accelerometer or Depth sensor) used to record the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Shape of accelerometer recording window with data values: ', training_records[training_records.sensor == 'acc'].iloc[0]['df'].shape)\n",
    "print('Shape of depth sensor recording window with data values: ', training_records[training_records.sensor == 'dc'].iloc[0]['df'].shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Accelerometer data\n",
    "\n",
    "Accelerometer data consist of readings of 3 accelerometer axis. Fist column represents time series and other 3 accelerometer axis. Values in the of the first sample range from -0.8 to 0.85, sou roughly from -1 to 1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(training_records[training_records.sensor == 'acc'].iloc[0]['df'])\n",
    "print(\"Minimal value of dataframe: \", np.min(training_records[training_records.sensor == 'acc'].iloc[0]['df'].values[:,1:]))\n",
    "print(\"Maximal value of dataframe: \", np.max(training_records[training_records.sensor == 'acc'].iloc[0]['df'].values[:,1:]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Depth sensor data\n",
    "\n",
    "The shape of data indicates that one window consists of 5 images with 192 features (pixels). There is also one more feature, for time label. Values in the of the first sample range from 0 to 0.96, so roughly from 0 to 1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(training_records[training_records.sensor == 'dc'].iloc[0]['df'])\n",
    "print(\"Minimal value of dataframe: \", np.min(training_records[training_records.sensor == 'dc'].iloc[0]['df'].values[:,1:]))\n",
    "print(\"Maximal value of dataframe: \", np.max(training_records[training_records.sensor == 'dc'].iloc[0]['df'].values[:,1:]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}