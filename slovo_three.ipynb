{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Feature extraction and feature-level fusion for multimodal classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='task3'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <b>Assigment.</b> <b>Task 3.</b>\n",
    "\n",
    "Prepare new feature sets for each modality and combine them to single feature representation. Compare two classifiers from scikit-learn. Train classifiers using joint feature presentation. Evaluate and compare the result using testing dataset. Do the subtasks given as\n",
    "<br>\n",
    "<br>\n",
    "<p> <b>3.1</b> Similar to task 2.1, calculate PCA for accelerometer, but choose now the 10 largest principal components as 10-dim feature vector for each window. In addition, for each window calculate mean and standard deviation of each three acc channels as statistical features, resulting 6-dimensional vector. Combine these to 36-dimensional final feature vector.</p>\n",
    "<br>\n",
    "<p> <b>3.2</b> Similar to task 2.2, calculate the PCA for depth images using same setup, but now choose the 10 largest principal components as feature vector. Concatenate the image sequence forming 50-dimensional feature vector from each windowed example.</p>\n",
    "<br>\n",
    "<p> <b>3.3</b> Form a joint feature presentation of features extracted in 3.1 and 3.2, resulting 86-dimensional feature vector for each example. Normalize data between 0-1 using the training dataset. Use support vector machine (SVM) with RBF-kernel and Gaussian naiveBayes classifier (use default parameter values for both classifiers). Train the classifiers and evaluate and compare classifiers on testset using confusion matrices and F1 scores.</p>\n",
    "<br>\n",
    "Document your work, evaluate the results, and analyse the outcomes in each subtasks 3.1-3.3.\n",
    "\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Task 3 imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import importlib, utilities.fun_three, utilities.fun_two, utilities.fun_one\n",
    "importlib.reload(utilities.fun_three)\n",
    "importlib.reload(utilities.fun_two)\n",
    "importlib.reload(utilities.fun_one)\n",
    "from utilities.fun_three import reshape_dataframe, Normalizer, merge_dataframes\n",
    "from utilities.fun_two import *\n",
    "from utilities.fun_one import visualize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Get the training data form the notebook slovo_one:\n",
    "%store -r training_records\n",
    "df_records_windowed = training_records\n",
    "%store -r testing_records\n",
    "df_records_windowed = testing_records"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 3.1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# 3.1\n",
    "### Your code begins here ###\n",
    "# Resample data:\n",
    "resample_samples = 125\n",
    "act_train = pd.DataFrame()\n",
    "act_train['df'] = acccelerometer_resample(training_records,resample_samples)\n",
    "train_labels = training_records[training_records.sensor_code=='act'].exercise_id.apply(lambda x: int(x))\n",
    "act_test = pd.DataFrame()\n",
    "act_test['df'] = acccelerometer_resample(testing_records,resample_samples)\n",
    "test_labels = testing_records[testing_records.sensor_code=='act'].exercise_id.apply(lambda x: int(x))\n",
    "\n",
    "#Standardize the Data:\n",
    "act_s = Standardizer()\n",
    "act_s.fit(act_train)\n",
    "act_train['df'] = act_s.transform(act_train)\n",
    "act_test['df'] = act_s.transform(act_test)\n",
    "\n",
    "\n",
    "n_components = 10\n",
    "pca = PcaActApplier(n_components)\n",
    "pca.fit(act_train['df'])\n",
    "act_pca_train = pca.transform(act_train['df'])\n",
    "act_pca_test = pca.transform(act_test['df'])\n",
    "\n",
    "act_features = np.concatenate((act_pca_train[0],act_pca_train[1],act_pca_train[2],\n",
    "                               np.mean(act_pca_train[0],axis=1).reshape(-1,1), np.std(act_pca_train[0],axis=1).reshape(-1,1),\n",
    "                               np.mean(act_pca_train[1],axis=1).reshape(-1,1), np.std(act_pca_train[1],axis=1).reshape(-1,1),\n",
    "                               np.mean(act_pca_train[2],axis=1).reshape(-1,1), np.std(act_pca_train[2],axis=1).reshape(-1,1),\n",
    "                              ),axis=1)\n",
    "\n",
    "act_test_features = np.concatenate((act_pca_test[0],act_pca_test[1],act_pca_test[2],\n",
    "                                    np.mean(act_pca_test[0],axis=1).reshape(-1,1), np.std(act_pca_test[0],axis=1).reshape(-1,1),\n",
    "                                    np.mean(act_pca_test[1],axis=1).reshape(-1,1), np.std(act_pca_test[1],axis=1).reshape(-1,1),\n",
    "                                    np.mean(act_pca_test[2],axis=1).reshape(-1,1), np.std(act_pca_test[2],axis=1).reshape(-1,1),\n",
    "                                   ),axis=1)\n",
    "\n",
    "pca_act_training_records_reshaped = deepcopy(training_records[training_records.sensor_code=='act'])\n",
    "pca_act_training_records_reshaped[\"df\"] = [act_feature for act_feature in act_features]\n",
    "pca_act_training_records_reshaped[\"df\"] = pca_act_training_records_reshaped.df.apply(np.expand_dims,axis=0)\n",
    "\n",
    "pca_act_testing_records_reshaped = deepcopy(testing_records[testing_records.sensor_code=='act'])\n",
    "pca_act_testing_records_reshaped[\"df\"] = [act_test_feature for act_test_feature in act_test_features]\n",
    "pca_act_testing_records_reshaped[\"df\"] = pca_act_testing_records_reshaped.df.apply(np.expand_dims,axis=0)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)\n",
    "### Your code ends here ###"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 3.2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3.2\n",
    "### Your code begins here ###\n",
    "'''Work only with rows with dc'''\n",
    "dc_train_records = training_records[training_records['sensor'] == 'dc']\n",
    "dc_test_records = testing_records[testing_records['sensor'] == 'dc']\n",
    "\n",
    "'''Initialize PCA for depth senspr'''\n",
    "reduced_dimensions = 10\n",
    "pca_applier = PcaDcApplier(reduced_dimensions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "'''Standardize the dc data'''\n",
    "standardizer = Standardizer()\n",
    "standardizer.fit(dc_train_records)\n",
    "standardized_dc_train_records = standardizer.transform(dc_train_records)\n",
    "standardized_dc_test_records = standardizer.transform(dc_test_records)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "'''Fit and transform PCA'''\n",
    "pca_applier.fit(standardized_dc_train_records)\n",
    "\n",
    "pca_dc_train_records = pca_applier.transform(standardized_dc_train_records)\n",
    "pca_dc_test_records = pca_applier.transform(standardized_dc_test_records)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "'''Reshape the dataframes for both train and test datasets '''\n",
    "pca_dc_train_records_reshaped = deepcopy(pca_dc_train_records)\n",
    "pca_dc_train_records_reshaped[\"df\"] = pca_dc_train_records_reshaped[\"df\"].apply(reshape_dataframe)\n",
    "dc_features = np.concatenate(pca_dc_train_records_reshaped['df'].values,axis=0)\n",
    "\n",
    "pca_dc_test_records_reshaped = deepcopy(pca_dc_test_records)\n",
    "pca_dc_test_records_reshaped[\"df\"] = pca_dc_test_records_reshaped[\"df\"].apply(reshape_dataframe)\n",
    "dc_test_features = np.concatenate(pca_dc_test_records_reshaped['df'].values,axis=0)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)\n",
    "### Your code ends here ###"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import importlib, utilities\n",
    "importlib.reload(utilities.fun_one)\n",
    "from utilities.fun_one import visualize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# 3.3\n",
    "### Your code begins here ###\n",
    "\n",
    "train_records_merged = pca_dc_train_records_reshaped.merge(pca_act_training_records_reshaped, on=['subject_id', 'exercise_id', 'trial', 'window_idx']).apply(merge_dataframes, axis=1)\n",
    "test_records_merged = pca_dc_test_records_reshaped.merge(pca_act_testing_records_reshaped, on=['subject_id', 'exercise_id', 'trial', 'window_idx']).apply(merge_dataframes, axis=1)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Save data for use in other notebooks:\n",
    "%store train_records_merged\n",
    "%store test_records_merged"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "'''Normalize the features'''\n",
    "normalizer = Normalizer()\n",
    "normalizer.fit(train_records_merged)\n",
    "\n",
    "normalized_train_records = normalizer.transform(train_records_merged)\n",
    "normalized_test_records = normalizer.transform(test_records_merged)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "'''Initialize and fit classifiers on training data'''\n",
    "gnb_classifier = GaussianNB()\n",
    "svm_classifier = SVC()\n",
    "\n",
    "gnb_classifier.fit(np.concatenate(normalized_train_records['df_normalized'].values,axis=0), normalized_train_records['exercise_id'].values)\n",
    "svm_classifier.fit(np.concatenate(normalized_train_records['df_normalized'].values,axis=0), normalized_train_records['exercise_id'].values)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "'''Get classifier predictions for test and train datasets'''\n",
    "gnb_est_train_labels = gnb_classifier.predict(np.concatenate(normalized_train_records['df_normalized'].values,axis=0))\n",
    "gnb_est_test_labels = gnb_classifier.predict(np.concatenate(normalized_test_records['df_normalized'].values,axis=0))\n",
    "\n",
    "svm_est_train_labels = svm_classifier.predict(np.concatenate(normalized_train_records['df_normalized'].values,axis=0))\n",
    "svm_est_test_labels = svm_classifier.predict(np.concatenate(normalized_test_records['df_normalized'].values,axis=0))\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Execution Time: \", end_time - start_time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''Visualize classification results. First for Gaussian naiveBayes classifier, then for SVM classifier'''\n",
    "visualize(gnb_est_train_labels,\n",
    "          normalized_train_records['exercise_id'].values,\n",
    "          gnb_est_test_labels,\n",
    "          normalized_test_records['exercise_id'].values,\n",
    "          main_title=\"GNB merged\")\n",
    "\n",
    "visualize(svm_est_train_labels,\n",
    "          normalized_train_records['exercise_id'].values,\n",
    "          svm_est_test_labels,\n",
    "          normalized_test_records['exercise_id'].values,\n",
    "          main_title=\"SVM merged\")\n",
    "\n",
    "### Your code ends here ###"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}